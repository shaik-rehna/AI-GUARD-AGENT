{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3bc781",
   "metadata": {},
   "source": [
    "# MILESTONE-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4828086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "import datetime\n",
    "\n",
    "\n",
    "log_file = \"command_log.txt\"\n",
    "\n",
    "def log_activity(spoken_text, status):\n",
    "    \"\"\"Save recognition result and activation status to a log file (ASCII safe).\"\"\"\n",
    "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"[{timestamp}] Heard: '{spoken_text}' --> {status}\\n\")\n",
    "    print(f\"[LOG] Heard: '{spoken_text}' --> {status}\")\n",
    "\n",
    "\n",
    "def activate_protect_mode():\n",
    "    \"\"\"Turn protect mode ON (one-way activation).\"\"\"\n",
    "    global protect_mode\n",
    "    if not protect_mode:\n",
    "        protect_mode = True\n",
    "        print(f\"[STATE] Protect Mode is now ON \")\n",
    "    else:\n",
    "        print(f\"[STATE] Already in Protect Mode\")\n",
    "\n",
    "\n",
    "def deactivate_protect_mode():\n",
    "    \"\"\"Turn protect mode OFF and stop listening.\"\"\"\n",
    "    global protect_mode, listening\n",
    "    if protect_mode:\n",
    "        protect_mode = False\n",
    "        print(f\"[STATE] Protect Mode is now OFF\")\n",
    "    else:\n",
    "        print(f\"[STATE] Already OFF\")\n",
    "    listening = False   # stop the loop in listen_for_command\n",
    "\n",
    "\n",
    "def listen_for_command():\n",
    "    \"\"\"Continuously listen for activation/deactivation commands via microphone.\"\"\"\n",
    "    global listening, total_commands, correct_commands\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "\n",
    "    with mic as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "    print(\"[INFO] Listening for commands: 'protect my room' to activate, 'stop' to deactivate.\")\n",
    "\n",
    "    while listening:   # loop runs only while listening == True\n",
    "        with mic as source:\n",
    "            audio = recognizer.listen(source, phrase_time_limit=5)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio).lower()\n",
    "            print(f\"[HEARD] {text}\")\n",
    "\n",
    "            if protect_mode == False:\n",
    "                total_commands += 1  # every recognized phrase counts\n",
    "\n",
    "            if \"protect my room\" in text:\n",
    "                activate_protect_mode()\n",
    "                log_activity(text, \"Activated\")\n",
    "                correct_commands += 1\n",
    "            else:\n",
    "                log_activity(text, \"No action\")\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            log_activity(\"Unrecognized speech\", \"No action\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"[ERROR] Could not request results from Google Speech API: {e}\")\n",
    "\n",
    "    # When loop ends â†’ show recognition accuracy\n",
    "    if total_commands > 0:\n",
    "        accuracy = (correct_commands / total_commands) * 100\n",
    "        print(f\"\\n[RESULT] Recognition Accuracy: {accuracy:.2f}% \"\n",
    "              f\"({correct_commands}/{total_commands})\")\n",
    "    else:\n",
    "        print(\"\\n[RESULT] No valid speech processed.\")\n",
    "\n",
    "\n",
    "def webcam_display():\n",
    "    \"\"\"Simple webcam feed to confirm video access.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"[ERROR] Cannot access webcam\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Show protect mode status on the frame\n",
    "        status_text = f\"Protect Mode: {'ON' if protect_mode else 'OFF'}\"\n",
    "        cv2.putText(frame, status_text, (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (0, 255, 0) if protect_mode else (0, 0, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Protect Agent Webcam\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"[INFO] 'q' pressed - shutting down...\")\n",
    "            deactivate_protect_mode()\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bce74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening for commands: 'protect my room' to activate, 'stop' to deactivate.\n",
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "[INFO] 'q' pressed - shutting down...\n",
      "[STATE] Already OFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "\n",
      "[RESULT] No valid speech processed.\n"
     ]
    }
   ],
   "source": [
    "# Global state\n",
    "protect_mode = False\n",
    "listening = True   # controls microphone loop\n",
    "\n",
    "# Accuracy tracking\n",
    "total_commands = 0\n",
    "correct_commands = 0\n",
    "\n",
    "# Clear old log file\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"=== Command Recognition Loag ===\\n\")\n",
    "\n",
    "# Run ASR in a separate thread\n",
    "threading.Thread(target=listen_for_command, daemon=True).start()\n",
    "# Run webcam display in main thread\n",
    "webcam_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3684e96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening for commands: 'protect my room' to activate, 'stop' to deactivate.\n",
      "[HEARD] protect my room\n",
      "[STATE] Protect Mode is now ON \n",
      "[LOG] Heard: 'protect my room' --> Activated\n",
      "[HEARD] show the product mode is\n",
      "[LOG] Heard: 'show the product mode is' --> No action\n",
      "[HEARD] impressing\n",
      "[LOG] Heard: 'impressing' --> No action\n",
      "[INFO] 'q' pressed - shutting down...\n",
      "[STATE] Protect Mode is now OFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "\n",
      "[RESULT] Recognition Accuracy: 100.00% (1/1)\n"
     ]
    }
   ],
   "source": [
    "# Global state\n",
    "protect_mode = False\n",
    "listening = True   # controls microphone loop\n",
    "\n",
    "# Accuracy tracking\n",
    "total_commands = 0\n",
    "correct_commands = 0\n",
    "\n",
    "# Clear old log file\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"=== Command Recognition Loag ===\\n\")\n",
    "\n",
    "# Run ASR in a separate thread\n",
    "threading.Thread(target=listen_for_command, daemon=True).start()\n",
    "# Run webcam display in main thread\n",
    "webcam_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee2ad1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0034b4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening for commands: 'protect my room' to activate, 'stop' to deactivate.\n",
      "[HEARD] protect my room\n",
      "[STATE] Protect Mode is now ON \n",
      "[LOG] Heard: 'protect my room' --> Activated\n",
      "[INFO] 'q' pressed - shutting down...\n",
      "[STATE] Protect Mode is now OFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "\n",
      "[RESULT] Recognition Accuracy: 100.00% (1/1)\n"
     ]
    }
   ],
   "source": [
    "# Global state\n",
    "protect_mode = False\n",
    "listening = True   # controls microphone loop\n",
    "\n",
    "# Accuracy tracking\n",
    "total_commands = 0\n",
    "correct_commands = 0\n",
    "\n",
    "# Clear old log file\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"=== Command Recognition Loag ===\\n\")\n",
    "\n",
    "# Run ASR in a separate thread\n",
    "threading.Thread(target=listen_for_command, daemon=True).start()\n",
    "# Run webcam display in main thread\n",
    "webcam_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7df51662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening for commands: 'protect my room' to activate, 'stop' to deactivate.\n",
      "[HEARD] protect my room\n",
      "[STATE] Protect Mode is now ON \n",
      "[LOG] Heard: 'protect my room' --> Activated\n",
      "[INFO] 'q' pressed - shutting down...\n",
      "[STATE] Protect Mode is now OFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "\n",
      "[RESULT] Recognition Accuracy: 100.00% (1/1)\n"
     ]
    }
   ],
   "source": [
    "# Global state\n",
    "protect_mode = False\n",
    "listening = True   # controls microphone loop\n",
    "\n",
    "# Accuracy tracking\n",
    "total_commands = 0\n",
    "correct_commands = 0\n",
    "\n",
    "# Clear old log file\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"=== Command Recognition Loag ===\\n\")\n",
    "\n",
    "# Run ASR in a separate thread\n",
    "threading.Thread(target=listen_for_command, daemon=True).start()\n",
    "# Run webcam display in main thread\n",
    "webcam_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcb5f8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening for commands: 'protect my room' to activate, 'stop' to deactivate.\n",
      "[HEARD] protect my room\n",
      "[STATE] Protect Mode is now ON \n",
      "[LOG] Heard: 'protect my room' --> Activated\n",
      "[INFO] 'q' pressed - shutting down...\n",
      "[STATE] Protect Mode is now OFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "\n",
      "[RESULT] Recognition Accuracy: 100.00% (1/1)\n"
     ]
    }
   ],
   "source": [
    "# Global state\n",
    "protect_mode = False\n",
    "listening = True   # controls microphone loop\n",
    "\n",
    "# Accuracy tracking\n",
    "total_commands = 0\n",
    "correct_commands = 0\n",
    "\n",
    "# Clear old log file\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"=== Command Recognition Loag ===\\n\")\n",
    "\n",
    "# Run ASR in a separate thread\n",
    "threading.Thread(target=listen_for_command, daemon=True).start()\n",
    "# Run webcam display in main thread\n",
    "webcam_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening for commands: 'protect my room' to activate, 'stop' to deactivate.\n",
      "[HEARD] protect my room\n",
      "[STATE] Protect Mode is now ON \n",
      "[LOG] Heard: 'protect my room' --> Activated\n",
      "[INFO] 'q' pressed - shutting down...\n",
      "[STATE] Protect Mode is now OFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "\n",
      "[RESULT] Recognition Accuracy: 100.00% (1/1)\n"
     ]
    }
   ],
   "source": [
    "# Global state\n",
    "protect_mode = False\n",
    "listening = True   # controls microphone loop\n",
    "\n",
    "# Accuracy tracking\n",
    "total_commands = 0\n",
    "correct_commands = 0\n",
    "\n",
    "# Clear old log file\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"=== Command Recognition Log ===\\n\")\n",
    "\n",
    "# Run ASR in a separate thread\n",
    "threading.Thread(target=listen_for_command, daemon=True).start()\n",
    "# Run webcam display in main thread\n",
    "webcam_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df4f0df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening for commands: 'protect my room' to activate, 'stop' to deactivate.\n",
      "[HEARD] protect my room\n",
      "[STATE] Protect Mode is now ON \n",
      "[LOG] Heard: 'protect my room' --> Activated\n",
      "[INFO] 'q' pressed - shutting down...\n",
      "[STATE] Protect Mode is now OFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Heard: 'Unrecognized speech' --> No action\n",
      "\n",
      "[RESULT] Recognition Accuracy: 100.00% (1/1)\n"
     ]
    }
   ],
   "source": [
    "# Global state\n",
    "protect_mode = False\n",
    "listening = True   # controls microphone loop\n",
    "\n",
    "# Accuracy tracking\n",
    "total_commands = 0\n",
    "correct_commands = 0\n",
    "\n",
    "# Clear old log file\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"=== Command Recognition Loag ===\\n\")\n",
    "\n",
    "# Run ASR in a separate thread\n",
    "threading.Thread(target=listen_for_command, daemon=True).start()\n",
    "# Run webcam display in main thread\n",
    "webcam_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17439593",
   "metadata": {},
   "source": [
    "* Average Accuracy = 100*5 / 5\n",
    "                   = 100 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511c467f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df9d2f",
   "metadata": {},
   "source": [
    "## MILESTONE-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dec21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\shaik rehna afroz\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.8.1.78)\n",
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\shaik rehna afroz\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.3)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\shaik rehna afroz\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (8.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\shaik rehna afroz\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (19.24.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shaik rehna afroz\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (11.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shaik rehna afroz\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: face-recognition-models, face_recognition\n",
      "\n",
      "   ---------------------------------------- 0/2 [face-recognition-models]\n",
      "   ---------------------------------------- 0/2 [face-recognition-models]\n",
      "   ---------------------------------------- 0/2 [face-recognition-models]\n",
      "   ---------------------------------------- 0/2 [face-recognition-models]\n",
      "   ---------------------------------------- 2/2 [face_recognition]\n",
      "\n",
      "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python face_recognition numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5413cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing e:\\7th sem\\ee782 adv topics in ml\\assignment_2\\dlib-19.24.1-cp311-cp311-win_amd64.whl\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.24.1\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install dlib-19.24.1-cp311-cp311-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b087f1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\shaik rehna afroz\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\shaik rehna afroz\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6463bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.8.1\n",
      "dlib version: 19.24.1\n",
      "face_recognition installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib, face_recognition\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"dlib version:\", dlib.__version__)\n",
    "print(\"face_recognition installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdbb266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Press 's' to capture face, 'q' to quit.\n",
      "[SAVED] Captured embedding #1 for Rehna\n",
      "[SAVED] Captured embedding #2 for Rehna\n",
      "[SAVED] Captured embedding #3 for Rehna\n",
      "[SAVED] Captured embedding #4 for Rehna\n",
      "[SAVED] Captured embedding #5 for Rehna\n",
      "[SAVED] Captured embedding #6 for Rehna\n",
      "[SAVED] Captured embedding #7 for Rehna\n",
      "[SAVED] Captured embedding #8 for Rehna\n",
      "[SAVED] Captured embedding #9 for Rehna\n",
      "[SAVED] Captured embedding #10 for Rehna\n",
      "[INFO] Total embeddings saved for Rehna: 10\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Directory to store trusted faces\n",
    "ENROLL_DIR = \"trusted_faces\"\n",
    "os.makedirs(ENROLL_DIR, exist_ok=True)\n",
    "\n",
    "# Capture from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"[INFO] Press 's' to capture face, 'q' to quit.\")\n",
    "\n",
    "# Ask for user name once\n",
    "user_name = input(\"Enter name for this user: \")\n",
    "\n",
    "# Load previous embeddings if exist\n",
    "user_file = os.path.join(ENROLL_DIR, f\"{user_name}.npy\")\n",
    "if os.path.exists(user_file):\n",
    "    embeddings = list(np.load(user_file, allow_pickle=True))\n",
    "    print(f\"[INFO] Loaded {len(embeddings)} existing embeddings for {user_name}\")\n",
    "else:\n",
    "    embeddings = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes = face_recognition.face_locations(rgb_frame)\n",
    "\n",
    "    # Draw boxes\n",
    "    for (top, right, bottom, left) in boxes:\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Enroll Trusted Face\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('s') and boxes:\n",
    "        # Take first face\n",
    "        top, right, bottom, left = boxes[0]\n",
    "\n",
    "        # Encode face using full frame + location\n",
    "        encs = face_recognition.face_encodings(rgb_frame, [(top, right, bottom, left)])\n",
    "        if encs:\n",
    "            embeddings.append(encs[0])\n",
    "            np.save(user_file, embeddings)\n",
    "            print(f\"[SAVED] Captured embedding #{len(embeddings)} for {user_name}\")\n",
    "        else:\n",
    "            print(\"[WARN] No face detected, try again.\")\n",
    "\n",
    "    elif key == ord('q'):\n",
    "        print(f\"[INFO] Total embeddings saved for {user_name}: {len(embeddings)}\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "489a2d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Press 's' to capture face, 'q' to quit.\n",
      "[SAVED] Captured embedding #1 for yashaswini\n",
      "[SAVED] Captured embedding #2 for yashaswini\n",
      "[SAVED] Captured embedding #3 for yashaswini\n",
      "[SAVED] Captured embedding #4 for yashaswini\n",
      "[SAVED] Captured embedding #5 for yashaswini\n",
      "[SAVED] Captured embedding #6 for yashaswini\n",
      "[SAVED] Captured embedding #7 for yashaswini\n",
      "[SAVED] Captured embedding #8 for yashaswini\n",
      "[SAVED] Captured embedding #9 for yashaswini\n",
      "[SAVED] Captured embedding #10 for yashaswini\n",
      "[SAVED] Captured embedding #11 for yashaswini\n",
      "[INFO] Total embeddings saved for yashaswini: 11\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Directory to store trusted faces\n",
    "ENROLL_DIR = \"trusted_faces\"\n",
    "os.makedirs(ENROLL_DIR, exist_ok=True)\n",
    "\n",
    "# Capture from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"[INFO] Press 's' to capture face, 'q' to quit.\")\n",
    "\n",
    "# Ask for user name once\n",
    "user_name = input(\"Enter name for this user: \")\n",
    "\n",
    "# Load previous embeddings if exist\n",
    "user_file = os.path.join(ENROLL_DIR, f\"{user_name}.npy\")\n",
    "if os.path.exists(user_file):\n",
    "    embeddings = list(np.load(user_file, allow_pickle=True))\n",
    "    print(f\"[INFO] Loaded {len(embeddings)} existing embeddings for {user_name}\")\n",
    "else:\n",
    "    embeddings = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes = face_recognition.face_locations(rgb_frame)\n",
    "\n",
    "    # Draw boxes\n",
    "    for (top, right, bottom, left) in boxes:\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Enroll Trusted Face\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('s') and boxes:\n",
    "        # Take first face\n",
    "        top, right, bottom, left = boxes[0]\n",
    "\n",
    "        # Encode face using full frame + location\n",
    "        encs = face_recognition.face_encodings(rgb_frame, [(top, right, bottom, left)])\n",
    "        if encs:\n",
    "            embeddings.append(encs[0])\n",
    "            np.save(user_file, embeddings)\n",
    "            print(f\"[SAVED] Captured embedding #{len(embeddings)} for {user_name}\")\n",
    "        else:\n",
    "            print(\"[WARN] No face detected, try again.\")\n",
    "\n",
    "    elif key == ord('q'):\n",
    "        print(f\"[INFO] Total embeddings saved for {user_name}: {len(embeddings)}\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89b90b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7044 sha256=d877c784475663776773b06e946d0aa526250899b17d89c98afb92d01ea79d21\n",
      "  Stored in directory: c:\\users\\shaik rehna afroz\\appdata\\local\\pip\\cache\\wheels\\50\\98\\42\\62753a9e1fb97579a0ce2f84f7db4c21c09d03bb2091e6cef4\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'playsound' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'playsound'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "! pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "395e2d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Trusted users: {'yashaswini', 'Rehna'}\n",
      "[INFO] Total embeddings: 21\n",
      "\n",
      "[INFO] Testing condition: background_noise\n",
      "[TEST] r1.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r2.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r3.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r4.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r5.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] y3.jpeg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y4.jpeg | True: yashaswini, Pred: yashaswini\n",
      "\n",
      "[INFO] Testing condition: bright_light\n",
      "[TEST] r1.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r10.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r11.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r12.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r13.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r14.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r18.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r19.jpg | True: Rehna, Pred: Unknown\n",
      "[TEST] r2.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r20.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r21.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r22.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r3.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r5.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r6.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r7.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] r8.jpeg | True: Rehna, Pred: Rehna\n",
      "[TEST] y1.jpeg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y10.jpeg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y11.jpeg | True: yashaswini, Pred: Unknown\n",
      "[TEST] y14.jpeg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y2.jpg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y3.jpg | True: yashaswini, Pred: yashaswini\n",
      "[INFO] No face detected in y4.jpg\n",
      "[TEST] y4.jpg | True: yashaswini, Pred: Unknown\n",
      "[TEST] y7.jpg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y8.jpg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y9.jpg | True: yashaswini, Pred: yashaswini\n",
      "\n",
      "[INFO] Testing condition: dim_light\n",
      "[TEST] r1.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r2.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r3.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r4.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r5.jpg | True: Rehna, Pred: Rehna\n",
      "[TEST] r6.jpg | True: Rehna, Pred: Unknown\n",
      "[TEST] y1.jpg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y2.jpg | True: yashaswini, Pred: yashaswini\n",
      "[INFO] No face detected in y3.jpg\n",
      "[TEST] y3.jpg | True: yashaswini, Pred: Unknown\n",
      "[TEST] y4.jpg | True: yashaswini, Pred: yashaswini\n",
      "[TEST] y5.jpg | True: yashaswini, Pred: yashaswini\n",
      "\n",
      "[INFO] Testing condition: unseen\n",
      "[TEST] a1.jpeg | True: Unknown, Pred: Unknown\n",
      "[TEST] b1.jpeg | True: Unknown, Pred: Unknown\n",
      "[TEST] p1.jpeg | True: Unknown, Pred: Unknown\n",
      "[TEST] p2.jpeg | True: Unknown, Pred: Unknown\n",
      "[TEST] p3.jpeg | True: Unknown, Pred: Unknown\n",
      "\n",
      "===== OVERALL RESULTS =====\n",
      "Accuracy : 0.9\n",
      "Precision: 0.95\n",
      "Recall   : 0.9\n",
      "F1 Score : 0.9130227001194743\n",
      "\n",
      "===== PER-CONDITION RESULTS =====\n",
      "background_noise -> Accuracy: 1.00\n",
      "bright_light -> Accuracy: 0.89\n",
      "dim_light -> Accuracy: 0.82\n",
      "unseen -> Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "ENROLL_DIR = \"trusted_faces\"\n",
    "TEST_DIR = \"test_cases\"\n",
    "\n",
    "trusted_encodings, trusted_names = [], []\n",
    "\n",
    "# Load trusted embeddings\n",
    "for file in os.listdir(ENROLL_DIR):\n",
    "    if file.endswith(\".npy\"):\n",
    "        path = os.path.join(ENROLL_DIR, file)\n",
    "        name = os.path.splitext(file)[0]\n",
    "        embeddings = np.load(path, allow_pickle=True)\n",
    "        for enc in embeddings:\n",
    "            trusted_encodings.append(enc)\n",
    "            trusted_names.append(name)\n",
    "\n",
    "print(f\"[INFO] Trusted users: {set(trusted_names)}\")\n",
    "print(f\"[INFO] Total embeddings: {len(trusted_encodings)}\")\n",
    "\n",
    "def get_true_label(filename):\n",
    "    prefix = filename[0].lower()\n",
    "    if prefix == \"r\":\n",
    "        return \"Rehna\"\n",
    "    elif prefix == \"y\":\n",
    "        return \"yashaswini\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Track metrics\n",
    "y_true_all, y_pred_all = [], []\n",
    "results_by_condition = defaultdict(lambda: {\"y_true\": [], \"y_pred\": []})\n",
    "\n",
    "# Loop through subfolders\n",
    "for condition in os.listdir(TEST_DIR):\n",
    "    condition_path = os.path.join(TEST_DIR, condition)\n",
    "    if not os.path.isdir(condition_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n[INFO] Testing condition: {condition}\")\n",
    "\n",
    "    for img_file in os.listdir(condition_path):\n",
    "        if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(condition_path, img_file)\n",
    "        true_label = get_true_label(img_file)\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"[WARNING] Could not load {img_file}\")\n",
    "            continue\n",
    "\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        boxes = face_recognition.face_locations(rgb_image)\n",
    "        encodings = face_recognition.face_encodings(rgb_image, boxes)\n",
    "\n",
    "        if len(encodings) == 0:\n",
    "            print(f\"[INFO] No face detected in {img_file}\")\n",
    "            y_pred = \"Unknown\"\n",
    "        else:\n",
    "            face_enc = encodings[0]\n",
    "            distances = face_recognition.face_distance(trusted_encodings, face_enc)\n",
    "\n",
    "            if len(distances) > 0:\n",
    "                min_idx = np.argmin(distances)\n",
    "                if distances[min_idx] < 0.45:\n",
    "                    y_pred = trusted_names[min_idx]\n",
    "                else:\n",
    "                    y_pred = \"Unknown\"\n",
    "            else:\n",
    "                y_pred = \"Unknown\"\n",
    "\n",
    "        # Append global + per-condition results\n",
    "        y_true_all.append(true_label)\n",
    "        y_pred_all.append(y_pred)\n",
    "        results_by_condition[condition][\"y_true\"].append(true_label)\n",
    "        results_by_condition[condition][\"y_pred\"].append(y_pred)\n",
    "\n",
    "        print(f\"[TEST] {img_file} | True: {true_label}, Pred: {y_pred}\")\n",
    "\n",
    "# === Overall Results ===\n",
    "print(\"\\n===== OVERALL RESULTS =====\")\n",
    "if len(y_true_all) > 0:\n",
    "    print(\"Accuracy :\", accuracy_score(y_true_all, y_pred_all))\n",
    "    print(\"Precision:\", precision_score(y_true_all, y_pred_all, average=\"weighted\", zero_division=0))\n",
    "    print(\"Recall   :\", recall_score(y_true_all, y_pred_all, average=\"weighted\", zero_division=0))\n",
    "    print(\"F1 Score :\", f1_score(y_true_all, y_pred_all, average=\"weighted\", zero_division=0))\n",
    "else:\n",
    "    print(\"[ERROR] No test results computed.\")\n",
    "\n",
    "# === Per Condition Results ===\n",
    "print(\"\\n===== PER-CONDITION RESULTS =====\")\n",
    "for condition, data in results_by_condition.items():\n",
    "    if len(data[\"y_true\"]) == 0:\n",
    "        continue\n",
    "    acc = accuracy_score(data[\"y_true\"], data[\"y_pred\"])\n",
    "    print(f\"{condition} -> Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61539d86",
   "metadata": {},
   "source": [
    "===== OVERALL RESULTS =====\n",
    "\n",
    "Accuracy : 0.9\n",
    "\n",
    "Precision: 0.95\n",
    "\n",
    "Recall   : 0.9\n",
    "\n",
    "F1 Score : 0.913\n",
    "\n",
    "===== PER-CONDITION RESULTS =====\n",
    "\n",
    "background_noise -> Accuracy: 1.00\n",
    "\n",
    "bright_light -> Accuracy: 0.89\n",
    "\n",
    "dim_light -> Accuracy: 0.82\n",
    "\n",
    "unseen -> Accuracy: 1.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418abc93",
   "metadata": {},
   "source": [
    "#### MILESTONE 3(entire integrated code) is in \"Milestone_3.py\" file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
